{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeKBz_AeAiVv"
      },
      "source": [
        "# Actividad para minimizar el impacto del sobre-ajuste.\n",
        "\n",
        "## Etapa 1: Definición de los datos.\n",
        "\n",
        "Antes de comenzar definimos la base de datos de interés. Usaremos la base de datos IMBD que consiste en reseñas hechas a 25000 películas. La tarea que configura esta base de datos consiste en predecir si el comentario es positivo o negativo. ([Ver enlace](https://keras.io/api/datasets/imdb/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7auJzvsB7MH"
      },
      "source": [
        "Se cargan las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-VmD4QoDB_Sf"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GtMxhTMCv2D"
      },
      "source": [
        "Se carga la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TiuLtdgE5bHs"
      },
      "outputs": [],
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqU7PDhC8vp"
      },
      "source": [
        "Se definen funciones para la visualización de la función de costo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0OItQv8mDDj_"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, history):\n",
        "    # Se evalúa el accuracy del modelo tanto en el conjunto de entrenamiento como \n",
        "    # en el de prueba.\n",
        "    _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "    _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "    print(f\"Trainining accuracy: {train_accuracy:.2f}\")\n",
        "    print(f\"Testing accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "    # Se grafica la función de costo para los conjuntos de entrenamiento y \n",
        "    # prueba.\n",
        "    plt.figure(figsize=(4, 3), dpi=160)\n",
        "\n",
        "    plt.plot(history.history[\"loss\"], label=\"train\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"test\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K0Cjgeul5v-7"
      },
      "outputs": [],
      "source": [
        "# Procesamiento de los datos.\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QP_X-UNw6Up9"
      },
      "outputs": [],
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3PR_gwJpDRHR"
      },
      "outputs": [],
      "source": [
        "# Se definen los conjuntos de entrenamiento y prueba\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YzBNSurn6YlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "00888923-a4d7-4b25-e9b4-56ff63fa63c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Se define la red neuronal.\\n\\nmodel = models.Sequential([\\n  layers.Dense(16, activation='relu', input_shape=(10000,)),\\n  layers.Dense(16, activation='relu'),\\n  layers.Dense(1, activation='sigmoid')\\n  ])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "'''\n",
        "# Se define la red neuronal.\n",
        "\n",
        "model = models.Sequential([\n",
        "  layers.Dense(16, activation='relu', input_shape=(10000,)),\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Tx91wJlV6c4u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5bd2d0aa-74af-46d0-98ee-284614137c6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel.compile(optimizer='rmsprop',\\n              loss='binary_crossentropy',\\n              metrics=['accuracy'])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "'''\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PzktYPMC6yuZ",
        "outputId": "82519fd9-3359-4e23-8c37-26755637c150"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhistory = model.fit(partial_x_train,\\n                    partial_y_train,\\n                    epochs=50,\\n                    batch_size=512,\\n                    validation_data=(x_val, y_val))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "'''\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kYpJHWTx7AYi"
      },
      "outputs": [],
      "source": [
        "#evaluate(model, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYJZQT-NzMu8"
      },
      "source": [
        "El modelo que entrenemos presenta sobre ajuste. Así, debemos construir una bitácora donde reportemos los siguientes análisis.  \n",
        " \n",
        "Indicar los elementos que tuvimos en cuenta para verificar que el modelo inicial se encuentra en sobreajuste. \n",
        "Modificar el modelo inicial con el fin de minimizar el impacto del sobreajuste y reportar los resultados obtenidos en términos de la función de pérdida. En particular debemos experimentar las siguientes variaciones: \n",
        "* Modelo inicial sin ninguna * modificación. \n",
        "* Modelo inicial añadiendo * regularización L2. \n",
        "* Modelo inicial añadiendo dropout. \n",
        "* Modelo que combine ambas estrategias de regularización. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Juan Esteban Floyd y Juan David Aycardi**"
      ],
      "metadata": {
        "id": "xGhLKxwGjuUA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIi8Nj2fycYL"
      },
      "source": [
        "# **BITACORA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZoljBzwy_-l"
      },
      "source": [
        "**Modelo inicial con ninguna modificacion:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgzpVrekzE3E",
        "outputId": "aa8f18d6-33ab-4ada-876d-a685ee4650e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "30/30 [==============================] - 7s 59ms/step - loss: 0.5602 - accuracy: 0.7723 - val_loss: 0.4425 - val_accuracy: 0.8530\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential([\n",
        "  layers.Dense(16, activation='relu', input_shape=(10000,)),\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O1H1MO0zU6m"
      },
      "outputs": [],
      "source": [
        "evaluate(model, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jNBu8JH0Za4"
      },
      "source": [
        "se puede evidenciar un sobreajuste ya que cuando se evalua el test con el modelo se ve que este esta muy alejado del valor de entrenamiento, cuando lo ideal es que estos esten lo mas cercano posible.\n",
        "Se puede decir que el modelo se aprendio datos anómalos y por este mismo el modelo aprende patrones generales y estos no ayudan a la prediccion de valores validos.\n",
        "En pocas palabras el modelo pierde la capacidad de generalizar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyGFRl_W1Zxm"
      },
      "source": [
        "**Modelo añadiendo regularizacion L2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCp9Xzlm2McM"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import numpy as np\n",
        "\n",
        "def build_model(regularization_rate):\n",
        "  model = models.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(10000,), kernel_regularizer=regularizers.l2(regularization_rate)),\n",
        "    layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(regularization_rate)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNNl7TOnN-iV"
      },
      "outputs": [],
      "source": [
        "model = KerasClassifier(build_fn=build_model)\n",
        "regularization_rates = [0.2]\n",
        "param_grid = dict(regularization_rate=regularization_rates)\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring=\"accuracy\")\n",
        "grid_result = grid.fit(partial_x_train, partial_y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tijyut6Sloh"
      },
      "outputs": [],
      "source": [
        "# Usar el mejor modelo encontrado para entrenar y evaluar\n",
        "best_model = build_model(grid_result.best_params_['regularization_rate'])\n",
        "history = best_model.fit(partial_x_train,\n",
        "                           partial_y_train,\n",
        "                           epochs=50,\n",
        "                           batch_size=32,\n",
        "                           validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QL-QcNtH2RFr"
      },
      "outputs": [],
      "source": [
        "evaluate(best_model, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbdouf4c46Ma"
      },
      "source": [
        "Se puede ver que añadiendo un valor en la regularizacion de x=0.2 el modelo tiene un compartamiento mucho mas parecido al esperado. Es decir, que el resultado del entrenamiento y el test sean lo mas parecido posible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vpc8Yqg4ll3"
      },
      "source": [
        "**Modelo inicial añadiendo dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCAe1Rde4q2Q"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import numpy as np\n",
        "\n",
        "def build_model(dropout):\n",
        "  model = Sequential([\n",
        "    layers.Dropout(dropout),\n",
        "    layers.Dense(16, activation='relu', input_shape=(10000,)),\n",
        "    layers.Dropout(dropout),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dropout(dropout),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=build_model)\n",
        "dropouts = [0.53]\n",
        "param_grid = dict(dropout = dropouts)\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring=\"accuracy\")\n",
        "grid_result = grid.fit(partial_x_train, partial_y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))  "
      ],
      "metadata": {
        "id": "RI26tu4Tb2ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el mejor modelo encontrado para entrenar y evaluar\n",
        "best_model = build_model(grid_result.best_params_['dropout'])\n",
        "history = best_model.fit(partial_x_train,\n",
        "                           partial_y_train,\n",
        "                           epochs=50,\n",
        "                           batch_size=32,\n",
        "                           validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "5Nnwzmafb3b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJdyMFkT5-Uh"
      },
      "outputs": [],
      "source": [
        "evaluate(best_model, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con una busqueda de parametros en el dropout de 0.4 se ve que tiende a normalizarse pero sigue estando muy alejado del valor esperado, es decir, sigue siendo mejor opcion la de aplicar regularizacion"
      ],
      "metadata": {
        "id": "dYTf101wsw55"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCpxpaKUJq2p"
      },
      "source": [
        "**Modelo que combina ambas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGgvP9SCJvtr"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import numpy as np\n",
        "\n",
        "def build_model(dropout, regularization_rate):\n",
        "  model = models.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(10000,), kernel_regularizer=regularizers.l2(regularization_rate)),\n",
        "    layers.Dropout(dropout),\n",
        "    layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(regularization_rate)),\n",
        "    layers.Dropout(dropout),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=build_model)\n",
        "regularization_rates = [0.145]\n",
        "dropouts = [0.4]\n",
        "param_grid = dict(regularization_rate=regularization_rates, dropout = dropouts)\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring=\"accuracy\")\n",
        "grid_result = grid.fit(partial_x_train, partial_y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))  "
      ],
      "metadata": {
        "id": "2NPhrlxVcfSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el mejor modelo encontrado para entrenar y evaluar\n",
        "best_model = build_model(dropout=grid_result.best_params_['dropout'],\n",
        "                          regularization_rate=grid_result.best_params_['regularization_rate'])\n",
        "history = best_model.fit(partial_x_train,\n",
        "                         partial_y_train,\n",
        "                         epochs=50,\n",
        "                         batch_size=32,\n",
        "                         validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "2uZ2oLalch47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1M2oBLdK0p6"
      },
      "outputs": [],
      "source": [
        "evaluate(best_model, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede ver que con un valor de regularizacion = 0.145 y con un valor de dropout = 0.4 la grafica tiende a tener un comportamiento como lo esperado, pero este no es tan bueno commo el de la regularizacion solo, es decir. Si bien se encuentra un buen valor, el compartamiento que se obtiene en esta no es la suficientemente bueno en comparacion a las diferentes alternativas."
      ],
      "metadata": {
        "id": "ThgVEOsdHynb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusiones:**"
      ],
      "metadata": {
        "id": "TR3H9_PPC45d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gracias a las formas que se vieron el clase de prevenir un sobreajuste se ve que ayuda bastante en su proposito ya que en el modelo se ven comportamientos parecidos en el entranamiento y en el test. Esto hace que el modelo tengo una buena capacidad generalizar. \n",
        "Es bastante efectivo el usar regularizacion y dropout pero tambien se videncio dificultades tecnicas y esto hace que debido a la limitaciones de recursos sea dificil de hacer una busqueda de hiperparamtetros y asi mismo, encontrar el mejor de estos mismos."
      ],
      "metadata": {
        "id": "btl7BtCWC8DJ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}